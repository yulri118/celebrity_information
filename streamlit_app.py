# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
import streamlit as st
import wikipediaapi
import wikipedia
import re
import time # API ìš”ì²­ ì‚¬ì´ì— ì•½ê°„ì˜ ì§€ì—°ì„ ì£¼ê¸° ìœ„í•´ ì¶”ê°€

# --- ì´ˆê¸° ì„¤ì • ---
wiki_wiki = wikipediaapi.Wikipedia(
    language='ko',
    user_agent='MyCelebrityApp/1.0 (youremail@example.com)'
)
wikipedia.set_lang('ko')

# --- ë„ìš°ë¯¸ í•¨ìˆ˜ (ì—…ê·¸ë ˆì´ë“œ ë° ì¶”ê°€) ---

# ì´ë¯¸ì§€ URLì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì¬ì‚¬ìš©)
def get_image_url(page):
    for image_url in page.images:
        if image_url.lower().endswith(('.jpg', '.jpeg', '.png')):
            return image_url
    return None

# í”„ë¡œí•„ ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜ (ì¬ì‚¬ìš©)
def extract_profile(summary):
    profile = {
        "ìƒë…„ì›”ì¼": "ì •ë³´ ì—†ìŒ",
        "ì¶œìƒ": "ì •ë³´ ì—†ìŒ",
        "ì§ì—…": "ì •ë³´ ì—†ìŒ",
        "ì†Œì† ê·¸ë£¹": "ì •ë³´ ì—†ìŒ"
    }
    sentences = summary.split('.')
    if not sentences: return profile
    first_sentence = sentences[0]

    birth_match = re.search(r'(\d{4}ë…„ \d{1,2}ì›” \d{1,2}ì¼)', summary)
    if birth_match: profile["ìƒë…„ì›”ì¼"] = birth_match.group(1)

    birthplace_match = re.search(r'ì˜\s*(\S+)\s*ì¶œì‹ ', first_sentence)
    if not birthplace_match: birthplace_match = re.search(r'(\S+)(íŠ¹ë³„|ê´‘ì—­|ë„|ì‹œ|êµ°|êµ¬)ì—ì„œ íƒœì–´ë‚œ', first_sentence)
    if birthplace_match: profile["ì¶œìƒ"] = birthplace_match.group(1).strip()

    if "ê°€ìˆ˜" in first_sentence: profile["ì§ì—…"] = "ê°€ìˆ˜"
    if "ë°°ìš°" in first_sentence: profile["ì§ì—…"] = "ë°°ìš°"
    if "ê°€ìˆ˜ ê²¸ ë°°ìš°" in first_sentence: profile["ì§ì—…"] = "ê°€ìˆ˜ ê²¸ ë°°ìš°"

    exo_match = re.search(r'EXO|ì—‘ì†Œ', first_sentence)
    if exo_match: profile["ì†Œì† ê·¸ë£¹"] = "EXO"
    
    return profile

# --- !!! ìƒˆë¡œ ì¶”ê°€ëœ í•µì‹¬ í•¨ìˆ˜ !!! ---
# 1. ì„¹ì…˜ í…ìŠ¤íŠ¸ì—ì„œ ì‘í’ˆ ëª©ë¡ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def parse_works_from_section(text):
    # ã€Šì‘í’ˆëª…ã€‹ ë˜ëŠ” 'ì‘í’ˆëª…' í˜•íƒœì˜ ì œëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    # í•œêµ­ ìœ„í‚¤í”¼ë””ì•„ëŠ” ì£¼ë¡œ ã€Šã€‹ ê´„í˜¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    works = re.findall(r'ã€Š([^ã€‹]+)ã€‹', text)
    return works

# 2. ì‘í’ˆëª…ìœ¼ë¡œ ìœ„í‚¤í”¼ë””ì•„ë¥¼ ë‹¤ì‹œ ê²€ìƒ‰í•´ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_image_for_work(work_title):
    try:
        # ì‘í’ˆëª…ìœ¼ë¡œ í˜ì´ì§€ ê²€ìƒ‰
        work_page = wikipedia.page(work_title, auto_suggest=False)
        # ìœ„í‚¤í”¼ë””ì•„ APIì— ê³¼ë¶€í•˜ë¥¼ ì£¼ì§€ ì•Šê¸° ìœ„í•´ ì ì‹œ ëŒ€ê¸°
        time.sleep(0.1) 
        # í•´ë‹¹ í˜ì´ì§€ì˜ ì´ë¯¸ì§€ URL ë°˜í™˜
        return get_image_url(work_page)
    except Exception:
        # í˜ì´ì§€ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜
        return None

# --- ì•± UI êµ¬ì„± ---

st.title("ğŸŒŸ ì „ì„¸ê³„ ì—°ì˜ˆì¸ ì‚¬ì „")

if 'search_history' not in st.session_state:
    st.session_state.search_history = []

celebrity_name = st.text_input("ì—°ì˜ˆì¸ ì´ë¦„ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ê±°ë‚˜ ê²€ìƒ‰ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
search_button = st.button("ê²€ìƒ‰")

if search_button or celebrity_name:
    if celebrity_name:
        try:
            page = wikipedia.page(celebrity_name, auto_suggest=False)
            
            if celebrity_name not in st.session_state.search_history:
                st.session_state.search_history.insert(0, celebrity_name)
                if len(st.session_state.search_history) > 10:
                    st.session_state.search_history.pop()

            st.header(page.title)

            col1, col2 = st.columns([1, 2])
            with col1:
                image_url = get_image_url(page)
                if image_url:
                    st.image(image_url, caption=page.title)
                else:
                    st.info("ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            with col2:
                st.subheader("ğŸ‘¤ í”„ë¡œí•„")
                profile_data = extract_profile(page.summary)
                for key, value in profile_data.items():
                    st.write(f"**{key}:** {value}")

            st.subheader("ğŸ“ ìš”ì•½ ì„¤ëª…")
            st.write(page.summary)

            # --- !!! ì‘í’ˆ ëª©ë¡ UI ì—…ê·¸ë ˆì´ë“œ !!! ---
            st.subheader("ğŸ¬ ëŒ€í‘œ ì‘í’ˆ ë° í™œë™")
            
            wiki_page = wiki_wiki.page(celebrity_name)
            keywords = ['í•„ëª¨ê·¸ë˜í”¼', 'ìŒë°˜', 'ì°¸ì—¬ ì‘í’ˆ', 'ì˜í™”', 'ë“œë¼ë§ˆ', 'ë®¤ì§€ì»¬', 'ê³µì—°']
            
            if wiki_page.exists():
                for section in wiki_page.sections:
                    for keyword in keywords:
                        if keyword in section.title:
                            # 1. ì„¹ì…˜ ì œëª©ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥í•œ ì˜ì—­(expander)ì„ ë§Œë“­ë‹ˆë‹¤.
                            with st.expander(f"**{section.title}** ëª©ë¡ ë³´ê¸°"):
                                # 2. ì„¹ì…˜ ë³¸ë¬¸ì—ì„œ ì‘í’ˆëª… ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
                                works_list = parse_works_from_section(section.text)
                                
                                if not works_list:
                                    st.write("ì´ ì„¹ì…˜ì—ì„œ ì‘í’ˆëª…ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                                    st.text(section.text[:500] + "...") # ëŒ€ì‹  ì›ë³¸ í…ìŠ¤íŠ¸ ì¼ë¶€ í‘œì‹œ
                                    continue

                                # 3. ì¶”ì¶œëœ ì‘í’ˆëª… í•˜ë‚˜í•˜ë‚˜ì— ëŒ€í•´ ì´ë¯¸ì§€ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.
                                for work in works_list:
                                    work_col1, work_col2 = st.columns([1, 3])
                                    with work_col1:
                                        # ì‘í’ˆ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
                                        work_image_url = get_image_for_work(work)
                                        if work_image_url:
                                            st.image(work_image_url)
                                        else:
                                            st.image("https://via.placeholder.com/150x200.png?text=No+Image", use_column_width=True) # ëŒ€ì²´ ì´ë¯¸ì§€
                                    with work_col2:
                                        st.markdown(f"**{work}**")
                                    st.divider() # ì‘í’ˆë³„ êµ¬ë¶„ì„ 
                            break # í‚¤ì›Œë“œë¥¼ ì°¾ìœ¼ë©´ ë‹¤ìŒ ì„¹ì…˜ìœ¼ë¡œ ì´ë™

        except wikipedia.exceptions.PageError:
            st.error(f"'{celebrity_name}'ì— ëŒ€í•œ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except wikipedia.exceptions.DisambiguationError as e:
            st.warning(f"ê²€ìƒ‰ì–´ê°€ ì—¬ëŸ¬ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤. ì¢€ ë” ìì„¸í•˜ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: {e.options[0]}, {e.options[1]})")
        except Exception as e:
            st.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# --- ì‚¬ì´ë“œë°” UI ---
st.sidebar.title("ìµœê·¼ ê²€ìƒ‰ ê¸°ë¡")
if not st.session_state.search_history:
    st.sidebar.info("ì•„ì§ ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    for item in st.session_state.search_history:
        st.sidebar.write(item)